# -*- coding: utf-8 -*-
"""InvestmentThesis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jX27ouejx-1l8eTAnopNlhWKkblyPqJ-

Install Libraries
"""

#python -m venv thesis_env
#source thesis_env/bin/activate  # (Windows: thesis_env\Scripts\activate)
!pip install google-generativeai langchain chromadb sentence-transformers pypdf2 streamlit langchain_text_splitters langchain-community

"""Import libraries"""

import os
import google.generativeai as genai

## Load API KEY

YOUR_GEMINI_API_KEY = "AIzaSyAUw0sjpM_tzVNduf1iyY-rG9yCO1ZoksI" # Make sure your actual API key is within quotes
os.environ["GOOGLE_API_KEY"] = YOUR_GEMINI_API_KEY # Use the variable, not the placeholder string
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

"""Document Loader Setup"""

import os
from PyPDF2 import PdfReader

def load_documents(folder_path):
    docs = []
    processed_count = 0
    # Ensure the path exists and is a directory
    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):
        print(f"Warning: Folder path '{folder_path}' does not exist or is not a directory. Skipping.")
        return []

    for file_name in os.listdir(folder_path):
        if file_name.endswith(".pdf"):
            file_path = os.path.join(folder_path, file_name)
            try:
                reader = PdfReader(file_path)
                text = ""
                for page in reader.pages:
                    text += page.extract_text() or ""
                docs.append({"file_name": file_name, "text": text})
                processed_count += 1
            except Exception as e:
                print(f"Error processing {file_name}: {e}")
    print(f"Successfully processed {processed_count} PDF documents.")
    return docs

"""Chunking Setup"""

from langchain_text_splitters import RecursiveCharacterTextSplitter

def semantic_chunking(docs, chunk_size=800, overlap=150):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=["\n\n", "\n", ".", " "]
    )
    chunks = []
    for doc in docs:
        for chunk in splitter.split_text(doc["text"]):
            chunks.append({"text": chunk, "source": doc["file_name"]})
    return chunks

"""Vector SetUp"""

from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma

def build_vector_store(chunks, persist_directory="vector_db"):
    embedding_model = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
    vector_db = Chroma.from_texts(
        texts=[chunk["text"] for chunk in chunks],
        embedding=embedding_model,
        metadatas=[{"source": chunk["source"]} for chunk in chunks],
        persist_directory=persist_directory
    )
    vector_db.persist()
    return vector_db

"""Retrieval SetUp"""

def retrieve_context(vector_db, query, top_k=5):
    results = vector_db.similarity_search(query, k=top_k)
    context = "\n\n".join([r.page_content for r in results])
    return context

"""Prompt Template"""

def build_investment_prompt(company_name, context):
    prompt = f"""
YouYou are a senior investment analyst preparing a professional investment thesis.

Company: {company_name}

Context from research reports, filings, and market data:
{context}

Generate a structured investment thesis with the following sections:
1. **Company Overview**
2. **Market Opportunity**
3. **Competitive Positioning**
4. **Financial Performance**
5. **Risks & Mitigations**
6. **Investment Recommendation**

Guidelines:
- Use concise, factual, and analytical tone.
- Base insights strictly on the provided context.
- Avoid speculative statements.
- Format clearly with section headings.

RULES FOR EXTRACTION:

1. Only use financial values found in:

   - Consolidated Statement of Profit and Loss

   - Consolidated Balance Sheet

   - Consolidated Cash Flow Statement

3. If multiple values appear, use these tie-break rules:

   a. Prefer audited tables.

   b. Prefer the latest FY.

   c. Prefer numeric tables over narrative.

4. Return structured JSON only.

5. Include for each item:

   - value

   - unit

   - source_snippet (copy exact text)

   - page_number (if found)
 6. Refer to Analyst report for Investment Recommendation & generate the summary
"""
    return prompt

"""Generator SetUp"""

import google.generativeai as genai
#from prompt_template import build_investment_prompt

def generate_investment_thesis(company_name, context):
    prompt = build_investment_prompt(company_name, context)
    model = genai.GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    return response.text

#test code 1:
#test the above function - two PDFs are in the folder. Check if Text o/p has contets of bboth the pdfs
import os

pdf_folder_path = "/content/sample_data"

# Create the directory if it doesn't exist
if not os.path.exists(pdf_folder_path):
    os.makedirs(pdf_folder_path)
    print(f"Created directory: {pdf_folder_path}")
else:
    print(f"Directory already exists: {pdf_folder_path}")

# Now try loading documents
text = load_documents(pdf_folder_path)

# Display last 100 characters if text is not empty, otherwise indicate it's empty
if text:
    print(text[-100:])
else:
    print("No documents loaded (likely no PDFs in the directory or issue with folder path).")

#test code 2: "text" is the o/p of text_code_1 is now go for chunking
chunks = semantic_chunking(text)
chunks[-5:]

#test code 3: o/p of test_code_2 is now iput to db
#import importlib
#import vector_store
#importlib.reload(vector_store)
#from vector_store import build_vector_store
vector_db = build_vector_store(chunks)
#vector_db

#test code 4: lets search the DB now
#Here is problem! We are rteivinng chunks for a specific connext ad passing that to LLM. While LLM has
#wider prompts, but a specific/narrow context! Hence,ontext! Hence,ontext! Hence,ontext! Hence proper thesis generation fails.
#Solution - don't use RAG instead pass whole "text" (o/p of test code 1) to LLM. This "text" has everythig
context = retrieve_context(vector_db, "Consolidated financial statement of apple")
print(context) #o/p is coming correctly, it means DB is set up#

#test code 5: lets search the DB now
#If you put context = text then the RAG pipeline will be skipped and the thesis will be detailed
thesis = generate_investment_thesis("Apple", context)

print(thesis)

print(thesis)